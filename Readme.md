# Roman History Bot

Bot de conversaciÃ³n especializado en Historia Romana utilizando MLX (Apple Silicon) y el modelo Mistral-7B-Instruct.

## ğŸš€ CaracterÃ­sticas

- Respuestas en espaÃ±ol sobre Historia Romana
- Optimizado para Apple Silicon (M1/M2/M3)
- Procesamiento local (no requiere API externa)
- Sistema de memoria para mantener contexto de conversaciÃ³n
- Modelo cuantizado de 4-bit para eficiencia en memoria

## ğŸ“‹ Requisitos

- macOS con Apple Silicon (M1/M2/M3)
- Python 3.9+
- Poetry para gestiÃ³n de dependencias
- MÃ­nimo 16GB RAM recomendado

## ğŸ›  InstalaciÃ³n

1. Clonar el repositorio:
```bash
git clone <tu-repositorio>
cd roman_history_bot
```

2. Instalar dependencias con Poetry:
```bash
poetry install
```

3. Configurar variables de entorno:
```bash
# Crear archivo .env
HUGGINGFACE_TOKEN=tu_token_aquÃ­
```

## ğŸ’» Uso

1. Activar entorno virtual:
```bash
poetry shell
```

2. Ejecutar el bot interactivo:
```bash
poetry run python tests/test_interactive_memory.py
```

## ğŸ¤– Comandos Disponibles

- `historia`: muestra el historial de conversaciÃ³n
- `salir`: termina la sesiÃ³n

## ğŸ“¦ Estructura del Proyecto

```
roman_history_bot/
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ .env
â”œâ”€â”€ roman_history_bot/
â”‚   â”œâ”€â”€ bot/
â”‚   â”‚   â”œâ”€â”€ handlers.py
â”‚   â”‚   â””â”€â”€ roman_bot.py
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ settings.py
â””â”€â”€ tests/
    â””â”€â”€ test_interactive_memory.py
```

## ğŸ”§ ConfiguraciÃ³n

El bot utiliza las siguientes configuraciones por defecto:
- Modelo: mlx-community/Mistral-7B-Instruct-v0.3-4bit
- LÃ­mite de memoria: 3 interacciones
- Formato de respuesta: EspaÃ±ol, estilo acadÃ©mico

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor, asegÃºrate de:
1. Hacer fork del proyecto
2. Crear una rama para tu feature
3. Hacer commit de tus cambios
4. Crear un Pull Request

## ğŸ“„ Licencia

[Tu licencia aquÃ­]

## âœ¨ Agradecimientos

- MLX por el framework optimizado para Apple Silicon
- Comunidad MLX por la conversiÃ³n y optimizaciÃ³n del modelo Mistral
- Hugging Face por hosting del modelo