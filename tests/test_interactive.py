# tests/test_interactive_memory.py
from mlx_lm import load, generate
import mlx.core as mx
import time
from typing import List, Tuple

class RomanHistoryBot:
    def __init__(self, memory_limit: int = 3):
        self.model = None
        self.tokenizer = None
        self.model_id = "mlx-community/Mistral-7B-Instruct-v0.3-4bit"
        self.conversation_history: List[Tuple[str, str]] = []
        self.memory_limit = memory_limit
    
    def load_model(self):
        if self.model is None:
            print("ğŸ”„ Cargando modelo y tokenizer (esto puede tomar un minuto)...")
            load_start = time.time()
            self.model, self.tokenizer = load(self.model_id)
            print(f"âœ… Modelo cargado en {time.time() - load_start:.2f}s")
    
    def generate_response(self, question: str, temp: float = 0.7):
        if self.model is None:
            self.load_model()
        
        # Prompt mÃ¡s especÃ­fico y restrictivo
        prompt = f"""<s>[INST] Sistema: Eres un historiador experto del Imperio Romano. 
        Responde directamente a la pregunta sin saludos ni formalidades.
        MantÃ©n un tono acadÃ©mico y profesional.
        
        Contexto previo: {self._format_history() if self.conversation_history else 'Ninguno'}
        
        Pregunta: {question}
        [/INST]"""
        
        gen_start = time.time()
        response = generate(
            self.model,
            self.tokenizer,
            prompt=prompt,
            temp=temp,
            max_tokens=500
        )
        gen_time = time.time() - gen_start
        
        self.conversation_history.append((question, response))
        return response, gen_time
    
    def show_history(self):
        if not self.conversation_history:
            print("\nğŸ“ No hay historial de conversaciÃ³n.")
            return
            
        print("\nğŸ“ Historial de la conversaciÃ³n:")
        for i, (q, a) in enumerate(self.conversation_history, 1):
            print(f"\n=== InteracciÃ³n {i} ===")
            print(f"ğŸ‘¤ Pregunta: {q}")
            print(f"ğŸ¤– Respuesta: {a}")
            print("=" * 50)

    def _format_history(self) -> str:
        """Formatea el historial de conversaciÃ³n de manera concisa"""
        if not self.conversation_history:
            return ""
        
        history = []
        for q, a in self.conversation_history[-self.memory_limit:]:
            history.append(f"P: {q}\nR: {a}")
    
        return "\n".join(history)

    
def interactive_session():
    print("ğŸ›ï¸ Bot de Historia Romana - SesiÃ³n Interactiva")
    print("=" * 50)
    print("Comandos disponibles:")
    print("- 'historia': muestra el historial de la conversaciÃ³n")
    print("- 'creativo': aumenta la creatividad de las respuestas")
    print("- 'preciso': hace las respuestas mÃ¡s precisas")
    print("- 'salir': termina la sesiÃ³n")
    print("=" * 50)
    
    bot = RomanHistoryBot(memory_limit=3)
    temperature = 0.7  # Temperatura por defecto
    
    while True:
        try:
            question = input("\nğŸ‘¤ Tu pregunta: ").strip().lower()
            
            if question == 'salir':
                print("\nÂ¡Vale! Â¡Hasta luego!")
                break
                
            if question == 'historia':
                bot.show_history()
                continue
                
            if question == 'creativo':
                temperature = min(temperature + 0.1, 1.0)
                print(f"\nğŸ¨ Aumentando creatividad (temperatura: {temperature:.1f})")
                continue
                
            if question == 'preciso':
                temperature = max(temperature - 0.1, 0.1)
                print(f"\nğŸ¯ Aumentando precisiÃ³n (temperatura: {temperature:.1f})")
                continue
            
            if not question:
                print("Por favor, escribe una pregunta.")
                continue
            
            print("\nğŸ¤– Generando respuesta...")
            response, gen_time = bot.generate_response(question, temp=temperature)
            
            print("\nâœ¨ Respuesta:")
            print(response)
            print(f"\nâ±ï¸ Tiempo de generaciÃ³n: {gen_time:.2f}s")
            print(f"ğŸ¨ Temperatura actual: {temperature:.1f}")
            print(f"ğŸ“š Conversaciones en memoria: {len(bot.conversation_history)}")
            
        except KeyboardInterrupt:
            print("\n\nÂ¡Hasta luego!")
            break
        except Exception as e:
            print(f"\nâŒ Error: {str(e)}")

if __name__ == "__main__":
    interactive_session()